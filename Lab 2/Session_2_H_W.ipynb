{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name: Shrook Ehab Attia\n",
    "# AI Nasr City Intake 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIwZsU0haNkj"
   },
   "source": [
    "## Task 1 - SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45wCuSvgajao"
   },
   "source": [
    "### Build SparkSession:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JwcbnqiymCE3"
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8HITwTqnJcX"
   },
   "source": [
    "### Read the json file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "93iqAB7tnMYQ"
   },
   "outputs": [],
   "source": [
    "df_samples = spark.read.json('DataFrames_sample.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNx0qMfunbKX"
   },
   "source": [
    "### Display the schema:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UG4CcVJenc9y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- D: double (nullable = true)\n",
      " |-- H: double (nullable = true)\n",
      " |-- HDD: string (nullable = true)\n",
      " |-- Id: long (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- RAM: string (nullable = true)\n",
      " |-- ScreenSize: string (nullable = true)\n",
      " |-- W: double (nullable = true)\n",
      " |-- Weight: double (nullable = true)\n",
      " |-- Year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_samples.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zaj0nHTcngEF"
   },
   "source": [
    "### Get all the data when \"Model\" equal \"MacBook Pro\":\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Vm9QPKBCnkuS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "|   D|   H|      HDD| Id|      Model| RAM|ScreenSize|    W|Weight|Year|\n",
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "|9.48|0.61|512GB SSD|  1|MacBook Pro|16GB|       15\"|13.75|  4.02|2015|\n",
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_samples.select('*').where(fn.col('Model') == 'MacBook Pro').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43oLte9LuGzA"
   },
   "source": [
    "### Create Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nVFYFcjtdIGW"
   },
   "outputs": [],
   "source": [
    "df_samples.createOrReplaceTempView('DataFrames_sample_json_file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCLMmjRLdjbT"
   },
   "source": [
    "### Display \"RAM\"column and count \"RAM\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n",
      "| ram|count(ram)|\n",
      "+----+----------+\n",
      "|64GB|         1|\n",
      "|16GB|         1|\n",
      "| 8GB|         2|\n",
      "+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select ram, count(ram) from DataFrames_sample_json_file group by ram\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5nlwq4t9gvK"
   },
   "source": [
    "### Get all columns when \"Year\" column equal \"2015\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "WXxjFxN19hJl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "|   D|   H|      HDD| Id|      Model| RAM|ScreenSize|    W|Weight|Year|\n",
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "|9.48|0.61|512GB SSD|  1|MacBook Pro|16GB|       15\"|13.75|  4.02|2015|\n",
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select * from DataFrames_sample_json_file where year=='2015'\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHjK2Kqfuv24"
   },
   "source": [
    "### Get all when \"Model\" start with \"M\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "m30EkY_iu1Gs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "|   D|   H|      HDD| Id|      Model| RAM|ScreenSize|    W|Weight|Year|\n",
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "|9.48|0.61|512GB SSD|  1|MacBook Pro|16GB|       15\"|13.75|  4.02|2015|\n",
      "|7.74|0.52|256GB SSD|  2|    MacBook| 8GB|       12\"|11.04|  2.03|2016|\n",
      "|8.94|0.68|128GB SSD|  3|MacBook Air| 8GB|     13.3\"| 12.8|  2.96|2016|\n",
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select * from DataFrames_sample_json_file where model like 'M%'\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Igw9iqJQ7TdH"
   },
   "source": [
    "### Get all data when \"Model\" column equal \"MacBook Pro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "SRCGSB_W9cPc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "|   D|   H|      HDD| Id|      Model| RAM|ScreenSize|    W|Weight|Year|\n",
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "|9.48|0.61|512GB SSD|  1|MacBook Pro|16GB|       15\"|13.75|  4.02|2015|\n",
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select * from DataFrames_sample_json_file where model=='MacBook Pro'\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZIlmJidw1Ep"
   },
   "source": [
    "### Get all data with Multiple Conditions when \"RAM\" column equal \"8GB\" and \"Model\" column is \"Macbook\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "-5T7roxgnBBV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---------+---+-------+---+----------+-----+------+----+\n",
      "|   D|   H|      HDD| Id|  Model|RAM|ScreenSize|    W|Weight|Year|\n",
      "+----+----+---------+---+-------+---+----------+-----+------+----+\n",
      "|7.74|0.52|256GB SSD|  2|MacBook|8GB|       12\"|11.04|  2.03|2016|\n",
      "+----+----+---------+---+-------+---+----------+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select * from DataFrames_sample_json_file where ram=='8GB' and model=='MacBook'\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qk8YPAWQ8HxI"
   },
   "source": [
    "### Get all data with Multiple Conditions when \"D\" greater than or equal \"8\" and \"Model\" column is \"iMac\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "XDHJSpQK9MuS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+---+-----+----+----------+----+------+----+\n",
      "|  D|   H|    HDD| Id|Model| RAM|ScreenSize|   W|Weight|Year|\n",
      "+---+----+-------+---+-----+----+----------+----+------+----+\n",
      "|8.0|20.3|1TB SSD|  4| iMac|64GB|       27\"|25.6|  20.8|2017|\n",
      "+---+----+-------+---+-----+----+----------+----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select * from DataFrames_sample_json_file where d>= 8 and model=='iMac'\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d6364f6"
   },
   "source": [
    "## Task 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlWhDvTPfZgu"
   },
   "source": [
    "### Read \"test1\" dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "7964d064"
   },
   "outputs": [],
   "source": [
    "df_test1 = spark.read.csv('test1.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJKjDOKHfnCt"
   },
   "source": [
    "### Display Salary of the people less than or equal to 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "c21edffc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Salary|\n",
      "+------+\n",
      "| 20000|\n",
      "| 20000|\n",
      "| 15000|\n",
      "| 18000|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test1.select('Salary').filter(df_test1['Salary'] <= 20000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Salary|\n",
      "+------+\n",
      "| 20000|\n",
      "| 20000|\n",
      "| 15000|\n",
      "| 18000|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test1.select('Salary').where(fn.col('Salary') <= 20000).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvFWNFJjf0Pq"
   },
   "source": [
    "### Display Salary of the people less than or equal to 20000 and greater than or equal 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "26f76ee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Salary|\n",
      "+------+\n",
      "| 20000|\n",
      "| 20000|\n",
      "| 15000|\n",
      "| 18000|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test1.select('Salary').filter((df_test1['Salary'] <= 20000) & (df_test1['Salary'] >= 15000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Salary|\n",
      "+------+\n",
      "| 20000|\n",
      "| 20000|\n",
      "| 15000|\n",
      "| 18000|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test1.select('Salary').where((fn.col('Salary') <= 20000) & (fn.col('Salary') >= 15000)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VAcIXkTgN9D"
   },
   "source": [
    "## Task 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOeqRO2KgW34"
   },
   "source": [
    "### Read \"test3\" dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "4d3bd081"
   },
   "outputs": [],
   "source": [
    "df_test3 = spark.read.csv('test3.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejyUT1rngdeR"
   },
   "source": [
    "### Display dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "7ed791ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+------+\n",
      "|     Name| Departments|salary|\n",
      "+---------+------------+------+\n",
      "|    Krish|Data Science| 10000|\n",
      "|    Krish|         IOT|  5000|\n",
      "|   Mahesh|    Big Data|  4000|\n",
      "|    Krish|    Big Data|  4000|\n",
      "|   Mahesh|Data Science|  3000|\n",
      "|Sudhanshu|Data Science| 20000|\n",
      "|Sudhanshu|         IOT| 10000|\n",
      "|Sudhanshu|    Big Data|  5000|\n",
      "|    Sunny|Data Science| 10000|\n",
      "|    Sunny|    Big Data|  2000|\n",
      "+---------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xp42YtorghXJ"
   },
   "source": [
    "### Display schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "d57d24ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Departments: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHxWeGCCgnww"
   },
   "source": [
    "### Group by \"Name\" column and using sum function on \"Name\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|     Name|sum(Name)|\n",
      "+---------+---------+\n",
      "|Sudhanshu|     null|\n",
      "|    Sunny|     null|\n",
      "|    Krish|     null|\n",
      "|   Mahesh|     null|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test3.groupBy('Name').agg(fn.sum('Name')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "f15f8197"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|     Name|sum(Salary)|\n",
      "+---------+-----------+\n",
      "|Sudhanshu|    35000.0|\n",
      "|    Sunny|    12000.0|\n",
      "|    Krish|    19000.0|\n",
      "|   Mahesh|     7000.0|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test3.groupBy('Name').agg(fn.sum('Salary')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWgkaU3bhUOL"
   },
   "source": [
    "### Group by \"Name\" column and using avg function on \"Name\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "fc122ace"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|     Name|avg(Name)|\n",
      "+---------+---------+\n",
      "|Sudhanshu|     null|\n",
      "|    Sunny|     null|\n",
      "|    Krish|     null|\n",
      "|   Mahesh|     null|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test3.groupBy('Name').agg(fn.avg('Name')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|     Name|       avg(Salary)|\n",
      "+---------+------------------+\n",
      "|Sudhanshu|11666.666666666666|\n",
      "|    Sunny|            6000.0|\n",
      "|    Krish| 6333.333333333333|\n",
      "|   Mahesh|            3500.0|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test3.groupBy('Name').agg(fn.avg('Salary')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARg_-WPKhfL5"
   },
   "source": [
    "### Group by \"Departments\" column and using sum function on \"Departments\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "151d2264"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+\n",
      "| Departments|sum(Departments)|\n",
      "+------------+----------------+\n",
      "|         IOT|            null|\n",
      "|    Big Data|            null|\n",
      "|Data Science|            null|\n",
      "+------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test3.groupBy('Departments').agg(fn.sum('Departments')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|sum(Salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|    15000.0|\n",
      "|    Big Data|    15000.0|\n",
      "|Data Science|    43000.0|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test3.groupBy('Departments').agg(fn.sum('Salary')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7rdLSEXhn4W"
   },
   "source": [
    "### Group by \"Departments\" column and using mean function on \"Departments\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "66fe5552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+\n",
      "| Departments|avg(Departments)|\n",
      "+------------+----------------+\n",
      "|         IOT|            null|\n",
      "|    Big Data|            null|\n",
      "|Data Science|            null|\n",
      "+------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test3.groupBy('Departments').agg(fn.mean('Departments')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|avg(Salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|     7500.0|\n",
      "|    Big Data|     3750.0|\n",
      "|Data Science|    10750.0|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test3.groupBy('Departments').agg(fn.mean('Salary')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bndivgGjhsbq"
   },
   "source": [
    "Group by \"Departments\" column and using count function on \"Departments\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "bc7bf192"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "| Departments|count(Departments)|\n",
      "+------------+------------------+\n",
      "|         IOT|                 2|\n",
      "|    Big Data|                 4|\n",
      "|Data Science|                 4|\n",
      "+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test3.groupBy('Departments').agg(fn.count('Departments')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfPs99wnhwGu"
   },
   "source": [
    "### Apply agg to using sum function get the total of salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "37b26cbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(Salary)|\n",
      "+-----------+\n",
      "|    73000.0|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test3.agg(fn.sum('Salary')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYD0wGPRi1FO"
   },
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJLc1PY1i-Np"
   },
   "source": [
    "You've been flown to their headquarters in Ulsan, South Korea, to assist them in accurately estimating the number of crew members a ship will need.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PEoknoejL4r"
   },
   "source": [
    "They're currently building new ships for certain customers, and they'd like you to create a model and utilize it to estimate how many crew members the ships will require.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70slYH-tjR81"
   },
   "source": [
    "Metadata:\n",
    "1. Measurements of ship size \n",
    "2. capacity \n",
    "3. crew \n",
    "4. age for 158 cruise ships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZzrhGnHkRCU"
   },
   "source": [
    "It is saved in a csv file for you called \"ITI_data.csv\". our task is to develop a regression model that will assist in predicting the number of crew members required for future ships. The client also indicated that they have found that particular cruise lines will differ in acceptable crew counts, thus this is most likely an important factor to consider when conducting your investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "A9CZzWWqZnOC"
   },
   "outputs": [],
   "source": [
    "df_iti_data = spark.read.csv('ITI_data.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "|  Ship_name|Cruise_line|Age|           Tonnage|passengers|length|cabins|passenger_density|crew|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "|    Journey|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
      "|      Quest|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
      "|Celebration|   Carnival| 26|            47.262|     14.86|  7.22|  7.43|             31.8| 6.7|\n",
      "|   Conquest|   Carnival| 11|             110.0|     29.74|  9.53| 14.88|            36.99|19.1|\n",
      "|    Destiny|   Carnival| 17|           101.353|     26.42|  8.92| 13.21|            38.36|10.0|\n",
      "|    Ecstasy|   Carnival| 22|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
      "|    Elation|   Carnival| 15|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
      "|    Fantasy|   Carnival| 23|            70.367|     20.56|  8.55| 10.22|            34.23| 9.2|\n",
      "|Fascination|   Carnival| 19|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
      "|    Freedom|   Carnival|  6|110.23899999999999|      37.0|  9.51| 14.87|            29.79|11.5|\n",
      "|      Glory|   Carnival| 10|             110.0|     29.74|  9.51| 14.87|            36.99|11.6|\n",
      "|    Holiday|   Carnival| 28|            46.052|     14.52|  7.27|  7.26|            31.72| 6.6|\n",
      "|Imagination|   Carnival| 18|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
      "|Inspiration|   Carnival| 17|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
      "|     Legend|   Carnival| 11|              86.0|     21.24|  9.63| 10.62|            40.49| 9.3|\n",
      "|   Liberty*|   Carnival|  8|             110.0|     29.74|  9.51| 14.87|            36.99|11.6|\n",
      "|    Miracle|   Carnival|  9|              88.5|     21.24|  9.63| 10.62|            41.67|10.3|\n",
      "|   Paradise|   Carnival| 15|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
      "|      Pride|   Carnival| 12|              88.5|     21.24|  9.63| 11.62|            41.67| 9.3|\n",
      "|  Sensation|   Carnival| 20|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_iti_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ship_name: string (nullable = true)\n",
      " |-- Cruise_line: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tonnage: double (nullable = true)\n",
      " |-- passengers: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- cabins: double (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_iti_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QTNLhZSlf9_"
   },
   "source": [
    "### OneHotEncoder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "-ZZxxxKLZnOF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 133 rows in the training set, and 25 in the test set\n"
     ]
    }
   ],
   "source": [
    "trainDF, testDF = df_iti_data.randomSplit([.8,.2],seed=42)\n",
    "print(f\"There are {trainDF.count()} rows in the training set, and {testDF.count()} in the test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ship_name', 'Cruise_line']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoricalCols = [field for (field, dataType) in trainDF.dtypes\n",
    "                  if dataType == 'string']\n",
    "categoricalCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'Tonnage', 'passengers', 'length', 'cabins', 'passenger_density']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericCols = [field for (field,dataType) in trainDF.dtypes\n",
    "              if ((dataType!='string')&(field!='crew'))]\n",
    "numericCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ship_name_Index', 'Cruise_line_Index']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexOutputCols = [x + \"_Index\" for x in categoricalCols]\n",
    "indexOutputCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ship_name_OHE', 'Cruise_line_OHE']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oheOutputCols = [x + \"_OHE\" for x in categoricalCols]\n",
    "oheOutputCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCols=categoricalCols,\n",
    "                              outputCols=indexOutputCols,\n",
    "                             handleInvalid='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "oheEncoder = OneHotEncoder(inputCols=indexOutputCols,\n",
    "                          outputCols=oheOutputCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNCxWem0l662"
   },
   "source": [
    "###Use VectorAssembler to merge all columns into one column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ship_name_OHE',\n",
       " 'Cruise_line_OHE',\n",
       " 'Age',\n",
       " 'Tonnage',\n",
       " 'passengers',\n",
       " 'length',\n",
       " 'cabins',\n",
       " 'passenger_density']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assemblerInputs = oheOutputCols + numericCols\n",
    "assemblerInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "pE4ohNjVZnOG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs,outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rbf56f6AmUUl"
   },
   "source": [
    "### Create a Linear Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "nvqnqTkunkNx"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol='features',\n",
    "                      labelCol='crew',\n",
    "                      predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVdxQTcSC6Cz"
   },
   "source": [
    "### Creating a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[stringIndexer,oheEncoder,\n",
    "                           vecAssembler,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineModel = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDF = pipelineModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "UqM9HxkNIHwE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ship_name: string (nullable = true)\n",
      " |-- Cruise_line: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tonnage: double (nullable = true)\n",
      " |-- passengers: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- cabins: double (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: double (nullable = true)\n",
      " |-- Ship_name_Index: double (nullable = false)\n",
      " |-- Cruise_line_Index: double (nullable = false)\n",
      " |-- Ship_name_OHE: vector (nullable = true)\n",
      " |-- Cruise_line_OHE: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+------------------+\n",
      "|            features|crew|        prediction|\n",
      "+--------------------+----+------------------+\n",
      "|(141,[26,119,135,...|12.0|14.827026154576883|\n",
      "|(141,[49,118,135,...|8.69|7.5507749324035265|\n",
      "|(141,[89,121,135,...| 6.3| 6.257969271425636|\n",
      "|(141,[9,134,135,1...|0.88|-2.843884120871538|\n",
      "|(141,[112,133,135...|1.97|-2.263445892994958|\n",
      "+--------------------+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.select('features','crew','prediction').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 is 0.5210674292468557\n"
     ]
    }
   ],
   "source": [
    "r2 = RegressionEvaluator(predictionCol='prediction',\n",
    "                                         labelCol='crew',\n",
    "                                         metricName='r2').evaluate(predDF)\n",
    "print(f\"R2 is {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SluXM6j-Gt9B"
   },
   "source": [
    "By Eng. Mostafa Nabieh \n",
    "If you have questions, please feel free to ask.\n",
    "\n",
    "My Email : nabieh.mostafa@yahoo.com\n",
    "\n",
    "My Whatsapp : +201015197566"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Session 2 H.W.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
